{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8994633e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Pytorch tutorial: Tensors, Autograd, and the Power of GPU Training\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    self-contained: true\n",
    "    number-sections: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c9b62",
   "metadata": {},
   "source": [
    "PyTorch was developed by Meta (formerly Facebook) and has become one of the most trusted frameworks for machine learning. It’s known for its flexibility, intuitive Pythonic design, and powerful tools such as tensors, autograd, and GPU acceleration.\n",
    "\n",
    "In this tutorial, we'll break down the key concepts of PyTorch step by step to help you build a solid foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90aed58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The PyTorch Ecosystem: An LLM Perspective\n",
    "\n",
    "PyTorch has a few core pillars. Here is how they map to NLP and LLM workflows:\n",
    "\n",
    "- **torch.Tensor**: The raw data (token IDs).\n",
    "- **torch.nn**: The layers (embeddings, transformers).\n",
    "- **torch.autograd**: The gradient calculator.\n",
    "- **torch.optim**: The weight updater (AdamW).\n",
    "- **torch.utils.data**: The batcher (DataLoaders).\n",
    "\n",
    "<!-- VISUAL: PYTORCH_ECOSYSTEM_FLOW -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ae906",
   "metadata": {},
   "source": [
    "# PyTorch Tensors - The Foundation\n",
    "\n",
    "Tensors are the fundamental data structures in PyTorch. Think of them as NumPy arrays but **can run on GPU and track gradients**\n",
    "\n",
    "Tensors are how data flows through neural networks—so understanding them is key.\n",
    "\n",
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6996eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating Tensors:\n",
      "From list: tensor([1, 2, 3, 4, 5])\n",
      "Zeros tensor shape: torch.Size([3, 4])\n",
      "Zeros tensor: tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Ones tensor shape: torch.Size([2, 3])\n",
      "Ones tensor: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Random tensor (normal):\n",
      "tensor([[-0.1400, -0.1690, -0.2229],\n",
      "        [ 1.7365,  1.4591, -0.0080]])\n",
      "Random tensor (uniform):\n",
      "tensor([[0.3295, 0.3835, 0.3816],\n",
      "        [0.5534, 0.3149, 0.8996]])\n",
      "From NumPy: tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors\n",
    "print(\"1.1 Creating Tensors:\")\n",
    "# From lists\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"From list: {tensor_from_list}\")\n",
    "\n",
    "# Zeros and ones\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "ones_tensor = torch.ones(2, 3)\n",
    "print(f\"Zeros tensor shape: {zeros_tensor.shape}\")\n",
    "print(f\"Zeros tensor: {zeros_tensor}\")\n",
    "print(f\"Ones tensor shape: {ones_tensor.shape}\")\n",
    "print(f\"Ones tensor: {ones_tensor}\")\n",
    "\n",
    "# Random tensors\n",
    "random_tensor = torch.randn(2, 3)  # Normal distribution\n",
    "uniform_tensor = torch.rand(2, 3)  # Uniform [0,1]\n",
    "print(f\"Random tensor (normal):\\n{random_tensor}\")\n",
    "print(f\"Random tensor (uniform):\\n{uniform_tensor}\")\n",
    "\n",
    "# From NumPy\n",
    "numpy_array = np.array([1, 2, 3, 4])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(f\"From NumPy: {tensor_from_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75203ac",
   "metadata": {},
   "source": [
    "## Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "719361ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.2 Tensor Properties:\n",
      "Shape: torch.Size([3, 4, 5])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Number of dimensions: 3\n",
      "Total elements: 60\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1.2 Tensor Properties:\")\n",
    "sample_tensor = torch.randn(3, 4, 5)\n",
    "print(f\"Shape: {sample_tensor.shape}\")\n",
    "print(f\"Data type: {sample_tensor.dtype}\")\n",
    "print(f\"Device: {sample_tensor.device}\")\n",
    "print(f\"Number of dimensions: {sample_tensor.ndim}\")\n",
    "print(f\"Total elements: {sample_tensor.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecbf083",
   "metadata": {},
   "source": [
    "## Tensor Operations\n",
    "\n",
    "### Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a480aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Element-wise Operations:\n",
      "a = tensor([1., 2., 3.])\n",
      "b = tensor([4., 5., 6.])\n",
      "a + b = tensor([5., 7., 9.])\n",
      "a - b = tensor([-3., -3., -3.])\n",
      "a * b = tensor([ 4., 10., 18.])\n",
      "a / b = tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "# Basic operations\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"1.3 Element-wise Operations:\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"a + b = {a + b}\")\n",
    "print(f\"a - b = {a - b}\")\n",
    "print(f\"a * b = {a * b}\")  # Element-wise multiplication\n",
    "print(f\"a / b = {a / b}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda6cb19",
   "metadata": {},
   "source": [
    "### Matrix Multiplication in Pytorch\n",
    "\n",
    "In PyTorch, **matrix multiplication is the backbone of most tensor computations**. It’s essential for speed, scalability, and expressing the math behind deep learning\n",
    "\n",
    "PyTorch supports matrix multiplication using several methods:\n",
    "\n",
    "- `@` operator (Pythonic and preferred for readability)\n",
    "- `torch.matmul()` (handles broadcasting and works for 1D, 2D, and batched tensors)\n",
    "- `torch.mm()` (only for 2D matrices)\n",
    "\n",
    "**Key differences:**\n",
    "\n",
    "- `@` and `torch.matmul()` can handle batched multiplication (e.g., 3D tensors).\n",
    "- `torch.mm()` is limited to 2D tensors and will raise an error for higher dimensions.\n",
    "\n",
    "All methods require that the **inner dimensions match**. For example, if `A` has shape `(batch_size, m, n)` and `B` has shape `(batch_size, n, p)`, then `A @ B` returns a tensor of shape `(batch_size, m, p)`.\n",
    "\n",
    "Always ensure that the inner dimensions match for matrix multiplication, e.g., `(m × n)` × `(n × p)` → `(m × p)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "738fc512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix1 shape: torch.Size([2, 3])\n",
      "Matrix2 shape: torch.Size([3, 4])\n",
      "Result shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "matrix1 = torch.randn(2, 3)\n",
    "matrix2 = torch.randn(3, 4)\n",
    "result = torch.mm(matrix1, matrix2)  # or matrix1 @ matrix2\n",
    "print(f\"Matrix1 shape: {matrix1.shape}\")\n",
    "print(f\"Matrix2 shape: {matrix2.shape}\")\n",
    "print(f\"Result shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4da40",
   "metadata": {},
   "source": [
    "### Reshaping Tensors for Matrix Multiplication\n",
    "\n",
    "When tensor dimensions don’t align for matrix multiplication, reshaping is often required. PyTorch provides several methods:\n",
    "\n",
    "- `.view(shape)` – Fast and memory-efficient, but only works on contiguous tensors.\n",
    "- `.reshape(shape)` – More flexible than `.view()`, can handle non-contiguous tensors.\n",
    "- `.unsqueeze(dim)` – Adds a dimension of size 1 (useful for promoting 1D tensors to 2D).\n",
    "- `.squeeze(dim)` – Removes dimensions of size 1.\n",
    "- `.flatten(start_dim, end_dim)` – Flattens dimensions into a single axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1fe2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3, 4])\n",
      "Reshaped: torch.Size([6, 4])\n",
      "Flattened: torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "# Matrix reshaping\n",
    "original = torch.randn(2, 3, 4)\n",
    "reshaped = original.view(6, 4)  # view() creates a new view\n",
    "flattened = original.flatten()   # flatten() to 1D\n",
    "print(f\"Original shape: {original.shape}\")\n",
    "print(f\"Reshaped: {reshaped.shape}\")\n",
    "print(f\"Flattened: {flattened.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a30fbe",
   "metadata": {},
   "source": [
    "### Tensor Indexing and Slicing in PyTorch\n",
    "\n",
    "Tensor indexing and slicing in PyTorch works very similarly to NumPy.\n",
    "\n",
    "#### Basic Indexing\n",
    "- `x[i]` – Access the i-th element along the first dimension.\n",
    "- `x[i, j]` – Access the element at row `i`, column `j`.\n",
    "- `x[i, :]` – All columns of row `i`.\n",
    "- `x[:, j]` – All rows of column `j`.\n",
    "\n",
    "#### Slicing\n",
    "- `x[start:stop]` – Slice along the first dimension.\n",
    "- `x[:, start:stop]` – Slice along other dimensions.\n",
    "- `x[..., j]` – Use `...` for flexible indexing (all leading dimensions).\n",
    "\n",
    "#### Negative Indices\n",
    "- `x[-1]` – Last element along the first dimension.\n",
    "- `x[:, -2:]` – Last two columns.\n",
    "\n",
    "#### Boolean Indexing\n",
    "- `mask = x > 0`  \n",
    "  `x[mask]` – Elements where the condition is `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a40a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([4, 5])\n",
      "First row: tensor([-0.5932,  1.5844, -0.7268,  0.9961,  0.7680])\n",
      "First column: tensor([-0.5932,  0.4300, -0.3191, -0.2829])\n",
      "Submatrix [1:3, 2:4]: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Matrix indexing and slicing\n",
    "tensor = torch.randn(4, 5)\n",
    "print(f\"Original tensor shape: {tensor.shape}\")\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Submatrix [1:3, 2:4]: {tensor[1:3, 2:4].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02594382",
   "metadata": {},
   "source": [
    "# Automatic Differentiation (Autograd)\n",
    "\n",
    "* Training a model requires calculating gradients. PyTorch handles this automatically using **Autograd**, its built-in automatic differentiation engine.\n",
    "\n",
    "* By default, PyTorch does not track operations on tensors. To enable gradient tracking for training, you must explicitly set `requires_grad=True` when creating a tensor.\n",
    "\n",
    "* Once enabled, PyTorch records all operations on that tensor to construct a computation graph.\n",
    "\n",
    "* Calling `.backward()` method to ask `PyTorch` to calculate the gradients, which are then stored in the `grad` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f2f1a",
   "metadata": {},
   "source": [
    "Let's define a simple function and compute its gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27bb589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = x² + 3x + 1\n",
      "dy/dx at x=2: tensor([7.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor that requires gradients\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Define the function\n",
    "y = x**2 + 3*x + 1\n",
    "print(f\"y = x² + 3x + 1\")\n",
    "\n",
    "# backpropagate to compute the gradient\n",
    "y.backward()  \n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(f\"dy/dx at x=2: {x.grad}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006505af",
   "metadata": {},
   "source": [
    "Multiple Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b17f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1., 2.], requires_grad=True)\n",
      "y = tensor([3., 4.], requires_grad=True)\n",
      "z = sum(x² + y²)\n",
      "dz/dx = tensor([2., 4.])\n",
      "dz/dy = tensor([6., 8.])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors with requires_grad=True so we can compute gradients w.r.t. them\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0, 4.0], requires_grad=True)\n",
    "\n",
    "# Compute a scalar z = x₁² + x₂² + y₁² + y₂²\n",
    "z = torch.sum(x**2 + y**2)  \n",
    "\n",
    "# Print the tensors and the computed scalar\n",
    "print(f\"x = {x}\")\n",
    "print(f\"y = {y}\")\n",
    "print(f\"z = sum(x² + y²)\")\n",
    "\n",
    "# Backpropagate to compute gradients dz/dx and dz/dy\n",
    "z.backward()\n",
    "\n",
    "# Print the gradients\n",
    "print(f\"dz/dx = {x.grad}\")  # Should be [2*x₁, 2*x₂] = [2, 4]\n",
    "print(f\"dz/dy = {y.grad}\")  # Should be [2*y₁, 2*y₂] = [6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c37edb",
   "metadata": {},
   "source": [
    "`grad_fn` enables PyTorch’s **autograd engine** to:\n",
    "\n",
    "- Trace the computation graph (a.k.a. dynamic computation graph)\n",
    "- Perform automatic differentiation (backpropagation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a371d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([8.3283, 0.3836, 1.0136], grad_fn=<AddBackward0>)\n",
      "y.grad_fn: <AddBackward0 object at 0x134da56f0>\n",
      "y_sum.grad_fn: <SumBackward0 object at 0x134da56f0>\n",
      "x.grad (after backward): tensor([ 4.4439, -1.1108,  3.0373])\n",
      "Grad_fn chain:\n",
      "   <SumBackward0 object at 0x134da56f0>\n",
      "   <AddBackward0 object at 0x1753c25f0>\n",
      "   <MulBackward0 object at 0x134da56f0>\n",
      "   <SinBackward0 object at 0x1753c25f0>\n",
      "   <AccumulateGrad object at 0x134da56f0>\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating grad_fn with a complex function\n",
    "x = torch.tensor([2.0, -1.0, 0.5], requires_grad=True)\n",
    "\n",
    "# Define a complex function: y = sin(x) * exp(x) + log(x**2 + 1)\n",
    "y = torch.sin(x) * torch.exp(x) + torch.log(x**2 + 1)\n",
    "\n",
    "print(\"y:\", y)\n",
    "print(\"y.grad_fn:\", y.grad_fn)  # This shows the grad_fn of the output tensor\n",
    "\n",
    "# If y is not a scalar, sum to get a scalar output for backward()\n",
    "y_sum = y.sum()\n",
    "print(\"y_sum.grad_fn:\", y_sum.grad_fn)\n",
    "\n",
    "y_sum.backward()\n",
    "print(\"x.grad (after backward):\", x.grad)\n",
    "\n",
    "# Show the grad_fn chain for y\n",
    "def print_grad_fn_chain(tensor):\n",
    "    fn = tensor.grad_fn\n",
    "    chain = []\n",
    "    while fn is not None:\n",
    "        chain.append(str(fn))\n",
    "        if hasattr(fn, 'next_functions') and fn.next_functions:\n",
    "            fn = fn.next_functions[0][0]\n",
    "        else:\n",
    "            break\n",
    "    print(\"Grad_fn chain:\")\n",
    "    for f in chain:\n",
    "        print(\"  \", f)\n",
    "\n",
    "print_grad_fn_chain(y_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c0350",
   "metadata": {},
   "source": [
    "## Gradient Accumulation in PyTorch\n",
    "\n",
    "- By default, **PyTorch accumulates gradients** in `.grad` fields — it does **not** overwrite them.\n",
    "- This is also the reason why we need to run `zero_grad()` in every training iteration (more on this later). Otherwise our gradients would keep building up from one training iteration to the other, which would cause our updates to be wrong.\n",
    "\n",
    "### When to call `zero_grad()`\n",
    "\n",
    "For standard (non-accumulation) training loops:\n",
    "\n",
    "```python\n",
    "for batch in dataloader:\n",
    "    optimizer.zero_grad()   # Clear old gradients\n",
    "    loss = model(batch)\n",
    "    loss.backward()         # Compute new gradients\n",
    "    optimizer.step()        # Update model parameters\n",
    "\n",
    "```\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1860d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After first backward: x.grad = tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# First computation\n",
    "y1 = x**2\n",
    "y1.backward()\n",
    "print(f\"After first backward: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb27de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After second backward: x.grad = tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "# Second computation (gradients accumulate!)\n",
    "y2 = x**3\n",
    "y2.backward()\n",
    "print(f\"After second backward: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d042d7",
   "metadata": {},
   "source": [
    "On the second backward pass, `x.grad` becomes `[5.]` because it **adds** the new gradient `3` (from `x³`) to the previous gradient `2` — so `2 + 3 = 5`.\n",
    "\n",
    "✅ **Tip**: To avoid unintended accumulation, reset gradients between steps with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7b608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After zeroing: x.grad = tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Clear gradients\n",
    "x.grad.zero_()\n",
    "print(f\"After zeroing: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86deb55",
   "metadata": {},
   "source": [
    "### When to Use Gradient Accumulation\n",
    "\n",
    "**Gradient accumulation** is useful when your model or hardware cannot handle large batch sizes due to memory constraints.\n",
    "\n",
    "Instead of updating model weights after every mini-batch, you can:\n",
    "1. Perform multiple forward/backward passes over smaller mini-batches.\n",
    "2. Accumulate gradients across these steps.\n",
    "3. Call `optimizer.step()` once after several steps to simulate a larger batch update.\n",
    "\n",
    "**Example:**  \n",
    "If your target batch size is 64, but your GPU can only handle batch size 16, you can accumulate gradients over 4 steps:\n",
    "\n",
    "```python\n",
    "accum_steps = 4\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    loss = model(batch)\n",
    "    loss.backward()  # Accumulate gradients\n",
    "\n",
    "    if (i + 1) % accum_steps == 0:\n",
    "        optimizer.step()        # Update model weights\n",
    "        optimizer.zero_grad()   # Clear gradients for next accumulation cycle\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff960d26",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing\n",
    "\n",
    "In NLP, the raw data is text. We'll create a tiny sentiment dataset, build a vocabulary, and convert sentences into token IDs that an embedding layer can consume.\n",
    "\n",
    "Since you've seen word2vec/GloVe, we'll also simulate pretrained vectors and plug them into `nn.Embedding` so the flow feels familiar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a toy NLP dataset and convert it into tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Toy NLP Dataset:\n",
      "Vocab size: 33\n",
      "Max sequence length: 6\n",
      "Training tensors: X=torch.Size([7, 6]), y=torch.Size([7])\n",
      "Validation tensors: X=torch.Size([1, 6]), y=torch.Size([1])\n",
      "Test tensors: X=torch.Size([2, 6]), y=torch.Size([2])\n",
      "Label distribution (train): tensor([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Toy NLP Dataset:\")\n",
    "data = [\n",
    "    (\"I love this class\", 1),\n",
    "    (\"Homework is hard\", 0),\n",
    "    (\"PyTorch makes sense\", 1),\n",
    "    (\"The lecture was confusing\", 0),\n",
    "    (\"I enjoy coding in Python\", 1),\n",
    "    (\"Deadlines are stressful\", 0),\n",
    "    (\"Transformers are powerful\", 1),\n",
    "    (\"I dislike debugging all night\", 0),\n",
    "    (\"This tutorial is helpful\", 1),\n",
    "    (\"The quiz was tricky\", 0),\n",
    "]\n",
    "\n",
    "tokenized_texts = [text.lower().split() for text, _ in data]\n",
    "\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for tokens in tokenized_texts:\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "max_len = 6\n",
    "\n",
    "def text_to_tensor(text, vocab, max_len):\n",
    "    tokens = text.lower().split()\n",
    "    ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "    if len(ids) < max_len:\n",
    "        ids = ids + [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "    return ids\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_end = int(0.7 * len(data))\n",
    "val_end = int(0.85 * len(data))\n",
    "train_data = data[:train_end]\n",
    "val_data = data[train_end:val_end]\n",
    "test_data = data[val_end:]\n",
    "\n",
    "def build_tensors(split_data):\n",
    "    texts = [text_to_tensor(text, vocab, max_len) for text, _ in split_data]\n",
    "    labels = [label for _, label in split_data]\n",
    "    return torch.LongTensor(texts), torch.FloatTensor(labels)\n",
    "\n",
    "X_train_tensor, y_train_tensor = build_tensors(train_data)\n",
    "X_val_tensor, y_val_tensor = build_tensors(val_data)\n",
    "X_test_tensor, y_test_tensor = build_tensors(test_data)\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Max sequence length: {max_len}\")\n",
    "print(f\"Training tensors: X={X_train_tensor.shape}, y={y_train_tensor.shape}\")\n",
    "print(f\"Validation tensors: X={X_val_tensor.shape}, y={y_val_tensor.shape}\")\n",
    "print(f\"Test tensors: X={X_test_tensor.shape}, y={y_test_tensor.shape}\")\n",
    "print(f\"Label distribution (train): {torch.bincount(y_train_tensor.long())}\")\n",
    "\n",
    "# Stand-in for pretrained word vectors (e.g., word2vec/GloVe)\n",
    "embed_dim = 16\n",
    "pretrained_embeddings = torch.randn(vocab_size, embed_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use `TensorDataset` to package your token IDs and labels together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDataset\n",
      "Dataset length: 7\n",
      "Sample item: (tensor([ 2, 25, 26, 27, 28,  0]), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorDataset\")\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Sample item: {dataset[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "Then use DataLoader to efficiently iterate through token batches.\n",
    "\n",
    "1. Batching\n",
    "- `TensorDataset` just holds the data.\n",
    "- `DataLoader` divides it into batches, which is crucial for training neural networks efficiently using mini-batch gradient descent.\n",
    "\n",
    "2. Shuffling\n",
    "- You can enable shuffling of data each epoch (e.g., `shuffle=True`), which helps improve generalization.\n",
    "\n",
    "3. Parallel Loading\n",
    "- `DataLoader` can use multiple worker threads (`num_workers`) to load data in parallel, improving performance for large datasets.\n",
    "\n",
    "4. Automatic Iteration\n",
    "- It returns an iterator, so you can use it in a `for` loop easily during training:\n",
    "\n",
    "```python\n",
    "for X_batch, y_batch in train_loader:\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 2\n",
      "Batch 1: X=torch.Size([4, 6]), y=torch.Size([4])\n",
      "Batch 2: X=torch.Size([3, 6]), y=torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Create data loader\n",
    "batch_size = 4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Number of batches: {len(dataloader)}\")\n",
    "\n",
    "# Iterate through batches\n",
    "for batch_idx, (batch_x, batch_y) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}: X={batch_x.shape}, y={batch_y.shape}\")\n",
    "    if batch_idx == 2:  # Show first 3 batches\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Dataset\n",
    "\n",
    "Use when loading from files, applying preprocessing, or handling complex logic.\n",
    "\n",
    "`torch.utils.data.Dataset` is an **abstract class** representing a dataset.  \n",
    "To create your own dataset, subclass `Dataset` and override the following two methods:\n",
    "\n",
    "- `__len__`: Returns the size of the dataset, so that `len(dataset)` works.\n",
    "- `__getitem__`: Supports indexing like `dataset[i]` to retrieve the *i-th* sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dataset:\n",
      "Custom dataset length: 7\n",
      "Custom dataloader batches: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom Dataset:\")\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Example of custom dataset class\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create custom dataset\n",
    "custom_dataset = SimpleDataset(X_train_tensor, y_train_tensor)\n",
    "custom_dataloader = DataLoader(custom_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print(f\"Custom dataset length: {len(custom_dataset)}\")\n",
    "print(f\"Custom dataloader batches: {len(custom_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580e3d8c",
   "metadata": {},
   "source": [
    "# Neural Network Modules in PyTorch\n",
    "\n",
    "PyTorch provides the `torch.nn` module to help you build and manage neural networks efficiently.\n",
    "\n",
    "At the core is the `nn.Module` class, which you subclass to define your own models.\n",
    "\n",
    "## Define Your Neural Network Architecture\n",
    "\n",
    "- **`nn.Module`** is the base class for all neural network models.  \n",
    "  Your model class must inherit from it.\n",
    "\n",
    "- In the constructor (`__init__`), define the layers and activation functions.  \n",
    "  Typically, layers and activations alternate (e.g., `Linear → ReLU → Linear`),  \n",
    "  except for the final layer which often omits activation depending on the task.\n",
    "\n",
    "- The **forward pass** is defined in the `forward()` method,  \n",
    "  which specifies how the input data flows through the layers.\n",
    "\n",
    "Example: A Bag-of-Words Classifier (Baby LLM)\n",
    "\n",
    "`nn.Embedding` is the bridge between integer token IDs and floating-point math: it maps each token to a learned vector so downstream layers can operate in continuous space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f3358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BagOfWordsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        if pretrained_embeddings is None:\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        pooled = embedded.mean(dim=1)\n",
    "        logits = self.fc(pooled)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb14a14",
   "metadata": {},
   "source": [
    "### Common Layers in `torch.nn`\n",
    "\n",
    "| Layer Type       | Description                               |\n",
    "|------------------|-------------------------------------------|\n",
    "| `nn.Linear`      | Fully connected (dense) layer             |\n",
    "| `nn.ReLU`        | Activation function (non-linear)          |\n",
    "| `nn.RNN`         | Basic recurrent layer for sequences       |\n",
    "| `nn.LSTM`        | Recurrent layer for sequences             |\n",
    "| `nn.Dropout`     | Randomly zeroes elements during training  |\n",
    "| `nn.BatchNorm`   | Normalizes input for stable training      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9f027",
   "metadata": {},
   "source": [
    "### Common Activation Functions\n",
    "\n",
    "- **Layers** (e.g., `Linear`, `Conv2d`) perform affine transformations:\n",
    "\n",
    " $$\n",
    "  \\text{output} = W x + b\n",
    " $$\n",
    "\n",
    "- Without a **non-linear activation**, stacking multiple layers is equivalent to a single linear transformation — the model won't be able to learn complex patterns.\n",
    "\n",
    "- **Activation functions** introduce non-linearity, allowing the model to approximate complex functions and decision boundaries.\n",
    "\n",
    "\n",
    "| Function       | PyTorch Module         | Description                          |\n",
    "|----------------|------------------------|--------------------------------------|\n",
    "| ReLU           | `nn.ReLU()`            | Most widely used; replaces negatives with 0 |\n",
    "| Sigmoid        | `nn.Sigmoid()`         | Squashes input to (0, 1); used in binary classification |\n",
    "| Tanh           | `nn.Tanh()`            | Squashes input to (-1, 1); zero-centered |\n",
    "| Leaky ReLU     | `nn.LeakyReLU()`       | Like ReLU but allows small gradient for negatives |\n",
    "| Softmax        | `nn.Softmax(dim=1)`    | Converts output to probability distribution (multiclass classification) |\n",
    "| GELU           | `nn.GELU()`            | Used in modern transformers; smooth alternative to ReLU |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f06d80",
   "metadata": {},
   "source": [
    "Instantiate the neural network model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1fd0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BagOfWordsClassifier(\n",
      "  (embedding): Embedding(33, 16)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# - vocab size = vocab_size\n",
    "# - embedding dimension = 16\n",
    "# - output classes = 1 (binary sentiment)\n",
    "num_classes = 1\n",
    "model = BagOfWordsClassifier(vocab_size, embed_dim, num_classes, pretrained_embeddings)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b5e18",
   "metadata": {},
   "source": [
    "output the model's architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9ba65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchsummary not installed. Skipping model summary.\n",
      "You can install it using: pip install torchsummary\n"
     ]
    }
   ],
   "source": [
    "# use torchsummary to get a summary of the model\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "\n",
    "    class _SummaryWrapper(nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x.long())\n",
    "\n",
    "    summary(_SummaryWrapper(model), input_size=(max_len,))\n",
    "except ImportError:\n",
    "    print(\"torchsummary not installed. Skipping model summary.\")\n",
    "    print(\"You can install it using: pip install torchsummary\")\n",
    "except Exception as exc:\n",
    "    print(f\"torchsummary failed on embedding inputs: {exc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45388648",
   "metadata": {},
   "source": [
    "### Using `nn.Sequential` in PyTorch\n",
    "\n",
    "For simple feedforward networks where layers are applied **in a fixed, linear order** (e.g., `Linear → ReLU → Linear`), `nn.Sequential` is a convenient and concise choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "670fba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(100, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f161bbd",
   "metadata": {},
   "source": [
    "However, `nn.Sequential` is **not suitable** when:\n",
    "\n",
    "- You need **conditionals**, **loops**, or **multiple inputs/outputs** in the `forward()` pass.\n",
    "- You want to **reuse layers** or apply layers in **non-sequential ways**.\n",
    "\n",
    "In such cases, define a custom model by subclassing `nn.Module`, which gives you full control over the forward logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61334c02",
   "metadata": {},
   "source": [
    "# Loss Functions and Optimization\n",
    "\n",
    "## Loss Functions\n",
    "\n",
    "\n",
    "Loss functions (also called **criteria**) measure how well the model's predictions match the true labels.  \n",
    "They guide the model during training by providing the gradient used in backpropagation.\n",
    "\n",
    "You can define a loss function in PyTorch using the `torch.nn` module:\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "###  Commonly Used Loss Functions in PyTorch (Preferred)\n",
    "\n",
    "| Task                      | Loss Function              | Output Shape                     | Notes                                                  |\n",
    "|---------------------------|----------------------------|----------------------------------|--------------------------------------------------------|\n",
    "| Binary classification     | `nn.BCEWithLogitsLoss()`   | `(batch_size, 1)`                |Combines `Sigmoid` + `BCELoss`             |\n",
    "| Multiclass classification | `nn.CrossEntropyLoss()`    | `(batch_size, num_classes)`      |Includes `LogSoftmax` internally           |\n",
    "| Regression                | `nn.MSELoss()`             | `(batch_size, 1)`                | Mean Squared Error (default choice for regression)     |\n",
    "| Regression                | `nn.L1Loss()`              | `(batch_size, 1)`                | Mean Absolute Error, more robust to outliers           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b74653",
   "metadata": {},
   "source": [
    "For classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75cbc97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to define loss functions and optimizers\n",
      "------------------------------------------------------------\n",
      "5.1 Common Loss Functions:\n",
      "Predictions shape: torch.Size([4, 3])\n",
      "True labels: tensor([0, 1, 2, 1])\n",
      "Cross-entropy loss function: CrossEntropyLoss()\n",
      "Cross-entropy loss: 0.8349\n"
     ]
    }
   ],
   "source": [
    "print(\"How to define loss functions and optimizers\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"5.1 Common Loss Functions:\")\n",
    "# Generate some dummy data\n",
    "batch_size = 4\n",
    "num_classes = 3\n",
    "\n",
    "# For classification\n",
    "predictions = torch.randn(batch_size, num_classes)\n",
    "true_labels = torch.tensor([0, 1, 2, 1])  # class indices\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"True labels: {true_labels}\")\n",
    "\n",
    "# Cross-entropy loss (for classification)\n",
    "ce_loss = nn.CrossEntropyLoss()  # Automatically applies softmax\n",
    "print(f\"Cross-entropy loss function: {ce_loss}\")\n",
    "loss_value = ce_loss(predictions, true_labels)\n",
    "print(f\"Cross-entropy loss: {loss_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05dd55",
   "metadata": {},
   "source": [
    "For regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d501062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss: 4.4705\n",
      "MAE loss: 1.5167\n"
     ]
    }
   ],
   "source": [
    "# For regression\n",
    "pred_values = torch.randn(batch_size, 1)\n",
    "true_values = torch.randn(batch_size, 1)\n",
    "\n",
    "# Mean squared error loss\n",
    "mse_loss = nn.MSELoss()\n",
    "mse_value = mse_loss(pred_values, true_values)\n",
    "print(f\"MSE loss: {mse_value:.4f}\")\n",
    "\n",
    "# Mean absolute error loss\n",
    "mae_loss = nn.L1Loss()\n",
    "mae_value = mae_loss(pred_values, true_values)\n",
    "print(f\"MAE loss: {mae_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c0fbf",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Optimizers in PyTorch are used to **update model parameters** based on gradients computed during backpropagation.\n",
    "\n",
    "They are part of `torch.optim` and are essential for training neural networks.\n",
    "\n",
    "You must define the optimizer yourself in PyTorch. There is no default — this gives you full flexibility, but also full responsibility.\n",
    "\n",
    "### Define the optimizer and pass in the model’s parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9757a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available optimizers:\n",
      "- SGD (Stochastic Gradient Descent)\n",
      "- RMSprop\n",
      "- Adam (Adaptive Moment Estimation)\n",
      "- AdamW (Adam with Weight Decay)\n",
      "- AdaGrad\n",
      "\n",
      "SGD optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "RMSprop optimizer: RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "Adam optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "AdamW optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Create a simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(5, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "print(\"Available optimizers:\")\n",
    "print(\"- SGD (Stochastic Gradient Descent)\")\n",
    "print(\"- RMSprop\")\n",
    "print(\"- Adam (Adaptive Moment Estimation)\")\n",
    "print(\"- AdamW (Adam with Weight Decay)\")\n",
    "print(\"- AdaGrad\")\n",
    "\n",
    "# Different optimizers\n",
    "sgd_optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "rmsprop_optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "adam_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "adamw_optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "\n",
    "print(f\"\\nSGD optimizer: {sgd_optimizer}\")\n",
    "print(f\"RMSprop optimizer: {rmsprop_optimizer}\")\n",
    "print(f\"Adam optimizer: {adam_optimizer}\")\n",
    "print(f\"AdamW optimizer: {adamw_optimizer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d03e1",
   "metadata": {},
   "source": [
    "###  Optimizer Step in PyTorch\n",
    "\n",
    "After choosing an optimizer, use `optimizer.step()` to **update the model parameters using the gradients computed during backpropagation**.\n",
    "\n",
    "This step applies the gradient updates to the model’s weights, moving them in the direction that **minimizes the loss**.\n",
    "\n",
    "####  Typical Workflow\n",
    "```python\n",
    "loss.backward()       # Compute gradients\n",
    "optimizer.step()      # Update model parameters\n",
    "optimizer.zero_grad() # Clear gradients before next step\n",
    "```\n",
    "\n",
    "Below is a simple training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c6e0d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step:\n",
      "Initial loss: 0.7855\n",
      "Loss after one step: 0.7855\n"
     ]
    }
   ],
   "source": [
    "# Dummy training data\n",
    "x_train = torch.randn(10, 5)\n",
    "y_train = torch.randn(10, 1)\n",
    "\n",
    "# Set up loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Training step:\")\n",
    "print(f\"Initial loss: {criterion(model(x_train), y_train).item():.4f}\")\n",
    "\n",
    "# One training step\n",
    "optimizer.zero_grad()    # Clear gradients\n",
    "outputs = model(x_train) # Forward pass\n",
    "loss = criterion(outputs, y_train)  # Compute loss\n",
    "loss.backward()          # Backward pass, compute gradients\n",
    "optimizer.step()         # Update parameters\n",
    "\n",
    "print(f\"Loss after one step: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d441ba0f",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "\n",
    "Inference is the process of using a trained model to make predictions on new, unseen data.\n",
    "Unlike training, inference does not require gradient tracking or parameter updates. \n",
    "\n",
    "## Steps for inference\n",
    "\n",
    "```python\n",
    "# 1. Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# 2. Disable gradient tracking\n",
    "with torch.no_grad():\n",
    "    # 3. Forward pass (X could be test data)\n",
    "    predictions = model(X)\n",
    "```\n",
    "\n",
    "Using the simple training example above, here is the inference code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Shapes in NLP\n",
    "\n",
    "Text batches become 3D tensors once tokens are embedded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP Batch Shape: torch.Size([32, 10, 256])\n"
     ]
    }
   ],
   "source": [
    "# (Batch_Size, Sequence_Length, Embedding_Dimension)\n",
    "dummy_batch = torch.randn(32, 10, 256)\n",
    "print(f\"NLP Batch Shape: {dummy_batch.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- VISUAL: TEXT_TO_NUMBERS_FLOW -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c217b",
   "metadata": {},
   "source": [
    "# The Complete  Loop\n",
    "\n",
    "Putting it all together - a full training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d183ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Data Preparation:\n",
      "Training data: torch.Size([7, 6])\n",
      "Validation data: torch.Size([1, 6])\n",
      "Test data: torch.Size([2, 6])\n",
      "Step 2: Model Definition:\n",
      "Model:\n",
      "BagOfWordsClassifier(\n",
      "  (embedding): Embedding(33, 16)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 545\n",
      "Trainable parameters: 545\n",
      "Step 3: Training Setup:\n",
      "Loss function: BCEWithLogitsLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Batch size: 4\n",
      "Step 4: Training Loop:\n",
      "Epoch [1/10], Train Loss: 0.6771, Val Loss: 0.6898\n",
      "Epoch [2/10], Train Loss: 0.6496, Val Loss: 0.7047\n",
      "Epoch [3/10], Train Loss: 0.6350, Val Loss: 0.7078\n",
      "Epoch [4/10], Train Loss: 0.6053, Val Loss: 0.7111\n",
      "Epoch [5/10], Train Loss: 0.5942, Val Loss: 0.7138\n",
      "Epoch [6/10], Train Loss: 0.5695, Val Loss: 0.7254\n",
      "Epoch [7/10], Train Loss: 0.5449, Val Loss: 0.7346\n",
      "Epoch [8/10], Train Loss: 0.5294, Val Loss: 0.7401\n",
      "Epoch [9/10], Train Loss: 0.5043, Val Loss: 0.7468\n",
      "Epoch [10/10], Train Loss: 0.4827, Val Loss: 0.7542\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Data Preparation:\")\n",
    "print(f\"Training data: {X_train_tensor.shape}\")\n",
    "print(f\"Validation data: {X_val_tensor.shape}\")\n",
    "print(f\"Test data: {X_test_tensor.shape}\")\n",
    "\n",
    "print(\"Step 2: Model Definition:\")\n",
    "vocab_size = len(vocab)\n",
    "# embed_dim defined above for pretrained embeddings\n",
    "num_classes = 1\n",
    "\n",
    "model = BagOfWordsClassifier(vocab_size, embed_dim, num_classes, pretrained_embeddings)\n",
    "\n",
    "print(f\"Model:\\n{model}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "print(\"Step 3: Training Setup:\")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "# Data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")\n",
    "print(f\"Batch size: 4\")\n",
    "\n",
    "print(\"Step 4: Training Loop:\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "model.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0.0\n",
    "    num_train_batches = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        logits = model(batch_x).squeeze(1)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "    avg_train_loss = epoch_train_loss / max(1, num_train_batches)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    num_val_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for val_x, val_y in val_loader:\n",
    "            val_logits = model(val_x).squeeze(1)\n",
    "            val_loss = criterion(val_logits, val_y)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "            num_val_batches += 1\n",
    "    avg_val_loss = epoch_val_loss / max(1, num_val_batches)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef5eb2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Visualizing Training:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Step 5: Visualizing Training:\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot learning curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00aa58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Evaluation:\n",
      "Test Loss: 0.6178\n",
      "Test Accuracy: 0.5000 (1/2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 6: Evaluation:\")\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    test_logits = model(X_test_tensor).squeeze(1)\n",
    "    test_loss = criterion(test_logits, y_test_tensor)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_probs = torch.sigmoid(test_logits)\n",
    "    predicted = (test_probs >= 0.5).long()\n",
    "    correct = (predicted == y_test_tensor.long()).sum().item()\n",
    "    accuracy = correct / len(y_test_tensor)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f} ({correct}/{len(y_test_tensor)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50172174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test_tensor.long().numpy(), predicted.numpy())\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e3d43b",
   "metadata": {},
   "source": [
    "# Model Saving and Loading\n",
    "\n",
    "Saving a model lets you reuse it later — for inference, continuing training, or deployment — without retraining.\n",
    "\n",
    "PyTorch provides flexible tools to save and load models.\n",
    "\n",
    "## Saving Models in PyTorch\n",
    "\n",
    "### Saving Models (Save the Model’s State Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ad07820",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf21e36",
   "metadata": {},
   "source": [
    "- Saves only the model’s **learned parameters** (not architecture)  \n",
    "- You must reconstruct the model when loading  \n",
    "- ✅ Best practice for **inference**, **deployment**, and **cross-version safety**  \n",
    "\n",
    "📁 Saved file: `'model_weights.pth'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ded519",
   "metadata": {},
   "source": [
    "### Save a Training Checkpoint (for Resuming Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c879bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': train_losses[-1],\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae39c56",
   "metadata": {},
   "source": [
    "- Saves everything needed to **resume training**  \n",
    "- Includes:\n",
    "  - Current epoch  \n",
    "  - Model parameters  \n",
    "  - Optimizer state  \n",
    "  - Last recorded loss  \n",
    "- ✅ Use this if you need to pause and resume training later  \n",
    "\n",
    "📁 Saved file: `'checkpoint.pth'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ab320",
   "metadata": {},
   "source": [
    "## Step 2: Loading Models\n",
    "\n",
    "### Load the state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db09ba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded model weights into new model\n"
     ]
    }
   ],
   "source": [
    "# Load state dict (need to create model first)\n",
    "new_model = BagOfWordsClassifier(vocab_size, embed_dim, num_classes)\n",
    "new_model.load_state_dict(torch.load('model_weights.pth'))\n",
    "print(\"✓ Loaded model weights into new model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f11d7d",
   "metadata": {},
   "source": [
    "### Load the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26a3b2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded checkpoint from epoch 10 with loss 0.4827\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "new_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(f\"✓ Loaded checkpoint from epoch {epoch} with loss {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f14e36",
   "metadata": {},
   "source": [
    "##  Step 3: Inference with Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d4aabb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs match: True\n",
      "Original predictions: tensor([0, 0])\n",
      "Loaded predictions: tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Inference with Loaded Model\n",
    "# Test that loaded model works\n",
    "new_model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_input = X_test_tensor[:5]  # First 5 test samples\n",
    "    original_output = model(sample_input)\n",
    "    loaded_output = new_model(sample_input)\n",
    "    \n",
    "    print(\"Outputs match:\", torch.allclose(original_output, loaded_output))\n",
    "    print(f\"Original predictions: {torch.argmax(original_output, dim=1)}\")\n",
    "    print(f\"Loaded predictions: {torch.argmax(loaded_output, dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f9a42",
   "metadata": {},
   "source": [
    "# GPU Usage\n",
    "\n",
    "PyTorch can train large models **much faster on a GPU than on a CPU**.\n",
    "However, you must **explicitly move** both your model and data to the GPU device.\n",
    "\n",
    "## Step 1: Check for GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4a064ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Checking GPU Availability:\n",
      "CUDA available: False\n",
      "CUDA not available - using CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Checking GPU Availability:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA not available - using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313d331",
   "metadata": {},
   "source": [
    "## Step 2:  Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f581d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Alternative way to check and set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c67380",
   "metadata": {},
   "source": [
    "## Step 3: Moving Tensors and Models to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b28f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3: Moving Tensors and Models to GPU:\n",
      "Original tensor device: cpu\n",
      "Tensor moved to: cpu\n",
      "Model moved to: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"step 3: Moving Tensors and Models to GPU:\")\n",
    "# Move tensors to device\n",
    "sample_tensor = torch.randn(3, 4)\n",
    "print(f\"Original tensor device: {sample_tensor.device}\")\n",
    "\n",
    "sample_tensor = sample_tensor.to(device)\n",
    "print(f\"Tensor moved to: {sample_tensor.device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(f\"Model moved to: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e86112",
   "metadata": {},
   "source": [
    "## Step 4: Common Training Loop with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90ea529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4:  GPU Training Template:\n",
      "Template for GPU training:\n",
      "\n",
      "# Setup\n",
      "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "model = model.to(device)\n",
      "\n",
      "# In training loop:\n",
      "for batch_x, batch_y in train_loader:\n",
      "    # Move data to device\n",
      "    batch_x = batch_x.to(device)\n",
      "    batch_y = batch_y.to(device)\n",
      "    \n",
      "    # Forward pass\n",
      "    outputs = model(batch_x)\n",
      "    loss = criterion(outputs, batch_y)\n",
      "    \n",
      "    # Backward pass\n",
      "    optimizer.zero_grad()\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"step 4:  GPU Training Template:\")\n",
    "print(\"Template for GPU training:\")\n",
    "print(\"\"\"\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# In training loop:\n",
    "for batch_x, batch_y in train_loader:\n",
    "    # Move data to device\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(batch_x)\n",
    "    loss = criterion(outputs, batch_y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5301cd",
   "metadata": {},
   "source": [
    "# Advanced Training Techniques in PyTorch\n",
    "\n",
    "## Learning Rate Scheduling\n",
    "\n",
    "### Learning rate affects convergence speed and stability\n",
    "\n",
    "* A high learning rate might cause the model to overshoot the minimum and never converge.\n",
    "* A low learning rate may result in slow learning or getting stuck in poor local minima.\n",
    "\n",
    "### Different training phases need different step sizes\n",
    "\n",
    "* In the early epochs, a **larger learning rate** helps make faster progress.\n",
    "\n",
    "* In the later epochs, a **smaller learning rate** allows fine-tuning around the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da5a530",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A **learning rate scheduler** dynamically adjusts the learning rate during training. This helps models converge faster and generalize better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993b2bd",
   "metadata": {},
   "source": [
    "`ReduceLROnPlateau` is a learning rate scheduler in PyTorch that reduces the learning rate when a monitored metric has stopped improving on validation set. This adaptive approach helps models escape local minima and achieve better convergence.\n",
    "\n",
    "Example: \n",
    "```python\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(...)\n",
    "    val_loss = validate(...)\n",
    "    scheduler.step(val_loss)\n",
    "```\n",
    "\n",
    "\n",
    "### Commom Schedulers\n",
    "\n",
    "| Scheduler                  | Description                                  |\n",
    "|---------------------------|----------------------------------------------|\n",
    "| `StepLR`                  | Decreases LR by a factor every N epochs      |\n",
    "| `ExponentialLR`           | Decays LR exponentially                      |\n",
    "| `ReduceLROnPlateau`       | Reduces LR when a metric has stopped improving |\n",
    "| `CosineAnnealingLR`       | Gradually lowers LR using cosine function     |\n",
    "| `OneCycleLR`              | Popular for fast convergence and stable training |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42914b",
   "metadata": {},
   "source": [
    "##  Advanced Optimizers: AdamW\n",
    "\n",
    "`AdamW` (Adam with decoupled Weight Decay) is an improved version of the standard Adam optimizer.  \n",
    "It was introduced to **fix a flaw in how Adam handles weight decay**, leading to better generalization and training stability.\n",
    "\n",
    "\n",
    "### Why Use AdamW?\n",
    "\n",
    "- In regular `Adam`, weight decay is applied as L2 penalty on the gradients, which interferes with Adam's adaptive learning rate.\n",
    "- `AdamW` **decouples weight decay** from the optimizer step and applies it **directly to the weights**, resulting in:\n",
    "  - Better regularization\n",
    "  - More stable and predictable convergence\n",
    "  - Superior performance in many modern models\n",
    "\n",
    "\n",
    "### When to Use AdamW\n",
    "\n",
    "- When using **weight decay** as a regularizer\n",
    "- When training **deep models**, including:\n",
    "  - Transformer-based NLP models\n",
    "  - ResNet and CNN architectures\n",
    "- When combining with **learning rate schedulers** like `CosineAnnealingLR` or `OneCycleLR`\n",
    "\n",
    "\n",
    "### How to Use in PyTorch\n",
    "\n",
    "```python\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "```\n",
    "\n",
    "AdamW was introduced as part of a research improvement [(Loshchilov & Hutter, 2019)](https://arxiv.org/abs/1711.05101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaab14c",
   "metadata": {},
   "source": [
    "## Combine Learning rate decay, weight decay, and `AdamW`\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(...)\n",
    "    scheduler.step()\n",
    "```\n",
    "\n",
    "✅ These tools are easy to integrate and can significantly boost model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f902a5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
